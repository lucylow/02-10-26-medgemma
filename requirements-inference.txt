# Lightweight inference (CPU-friendly for demo / edge)
# Install: pip install -r requirements-inference.txt
# No GPU required for running adapter inference with small batches.

torch>=2.1.0
transformers>=4.35.2
numpy
faiss-cpu
onnxruntime
onnx
pandas
pydantic>=1.10.0
